{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da610c6f-bad3-45bd-9750-ca1d6f120ace",
   "metadata": {},
   "source": [
    "# Chapter17. 스파크 베포 환경\n",
    "\n",
    "- 클러스터 배포 시 선택사항\n",
    "- 스파크가 지원하는 클러스터 매니저\n",
    "- 배포 시 고려사항과 배포 환경 설정\n",
    "사용자, 조직마다 활용 사례ㅡ 경험 그리고 컴퓨팅 자원은 다양 -> '어떤 클러스터 매니저가 사용하기 가장 쉽나요' 답하기는 어려움\n",
    "=> 스파크 공식 문서는 실행가능한 예제를 활영하여 배포 방식의 자세한 정보 제공(참고 권장)\n",
    "\n",
    "- 2017년 12월 기준 스파크는 공식적으로 세 가지 클러스터 매니저를 지원\n",
    "    -  스탠드얼론 모드\n",
    "    -  하둡 YARN\n",
    "    -  아파치 메소스\n",
    "- 클러스터 매니저: 스파크 애플리케이션을 배포해 실행할 수 있는 클러스터의 머신을 유지하고 관리\n",
    "- 공통점: 스파크 애플리케이션을 같은 방식으로 실행\n",
    "- 각 클러스터 매니저마다 추구하는 방향성이 다르기에 장단점을 이해하고 알맞게 사용할 것\n",
    "\n",
    "## 17.1 스파크 애플리케이션 실행을 위한 클러스터 환경\n",
    "- 설치형 클러스터(on-premise cluster)\n",
    "- 공개 클라우드(public cloud)\n",
    "\n",
    "### 17.1.1 설치형 클러스터 배포 환경\n",
    "- 자체 데이터센터를 운영하는 조직에 더 적합\n",
    "- 사용 중인 하드웨어를 완전히 제어할 수 있어 특정 워크로드의 성능을 최적화할 수 있음\n",
    "- 스파크 같은 데이터 분석 워크로드에서는 문제 발생 가능\n",
    "    - 설치형 클러스터의 크기는 제한적 <- 분석 워크로드에 필요한 자원은 상황에 따라 달라짐\n",
    "      (ex)클러스터를 너무 작게 -> 신규 머신러닝 모델을 학습하는 잡을 실행하기 어려움 / 클러스터를 너무 크게 -> 사용하지 않는 자원이 많아짐\n",
    "    - 하둡 파일 시스템이나 분산 키-값 저장소 같은 자체 저장소 시스템을 선택하고 운영해야 한다 => 상황에 따라 지리적 복제 및 재해 복구 체계도 함께 구축해야 한다.\n",
    "- 설치형 클러스터를 사용 시 자원 활용 문제를 해결할 수 있는 방법 -> 클러스터 매니저 사용\n",
    "- 클러스터 매니저를 사용 -> 다수의 스파크 애플리케이션을 실행 가능 + 애플리케이션의 자원을 동적으로 재할당 가능 + 하나의 클러스터에서 스파크 애플리케이션이 아닌 다른 프로그램을 실행 가능\n",
    "- 스파크가 지원하는 클러스터 매니저는 동시에 여러 애플리케이션 실행 가능\n",
    "    - YARN, 메소스는 동적 자원 공유 지원(스탠드얼른 모드 보다)\n",
    "- 여러 종류의 저장소 선택 가능\n",
    "\n",
    "### 17.2.3 클라우드 배포 환경\n",
    "- 초기 빅데이터 시스템은 설치형 클러스터에 적합하게 설계 -> 클라우드 환경이 일반적인 스파크 운영 플랫폼으로 자리 잡는 중\n",
    "- 클라우드 환경 빅데이터 워크로드 실행 시 장점\n",
    "    - 자원을 탄력적으로 사용 가능\n",
    "    - 공개 클라우드 환경은 비용이 저렴하고 지리적 복제 기능을 지원하는 저장소를 제공하기에 대규모 데이터 관리가 용이\n",
    "- AWS, Azure, GCP -> S3, Azure Blob, Google Cloud Storage 글로벌 저장소 시스템을 사용하고 스파크 워크로드 별 클러스터를 동적으로 할당하는 방식 추천\n",
    "- 연산 클러스터와 저장소 클러스터를 분리하면 연산이 필요한 경우에만 클러스터 비용을 지불 / 동적으로 크기 조절 가능 하드웨어 종류가 다른 클러스터를 섞어가며 사용 가능\n",
    "- 클라우드 환경에서 연산 관련 프로그램 및 환경을 관리할 필요가 없음 -> 클라우드 저장소를 연동해 스파크를 실행하면 클라우드의 유연성과 비용 절감 효과 그리고 관리 도구 등 다양한 장점 활용 가능\n",
    "\n",
    "## 17.2 클러스터 매니저\n",
    "### 17.2.1 스탠드얼론 모드\n",
    "- 아파치 스파크 워크로드용으로 특별히 제작된 경량화 플랫폼\n",
    "- 하나의 클러스터에 다수의 스파크 애플리케이션 실행 가능\n",
    "- 실행을 위한 간단한 인터페이스를 제공, 대형 스파크 워크로드로 확장 가능\n",
    "- 단점\n",
    "    - 다른 클러스터 매니저보다 제한적인 기능\n",
    "    - 스파크 애플리케이션만 실행 가능\n",
    "- 클러스터 환경을 빠르게 구축해 스파크 애플리케이션을 실행해야 하거나 YARN,메소스 사용 경험이 없다면 가장 좋은 선택지\n",
    "\n",
    "#### 스탠드얼론 클러스터 시작하기\n",
    "- 클러스터를 구성할 머신의 준비과정이 필요 - 네트워크 환경에서 클러스터를 구성하는 노드끼리 통신할 수 있어야 함\n",
    "- 실행할 버전의 스파크를 내려받아 전체 노드에 설치\n",
    "- 수동 실행 혹은 스파크에 내장된 스크립트를 이용해 클러스터틀 실행\n",
    "```\n",
    "$SPARK_HOME/sbin/start-master.sh\n",
    "```\n",
    "클러스터 매니저의 마스터 프로세스 실행 - spark://HOST:PORT 형식의 URI 출력 - 마스터 프로세스의 URI는 워커노드를 실행할 때 사용 - 클러스터의 애플리케이션 초기화 시 SparkSession의 --master 인수로 마스터 프로세스 URI를 사용 가능 - 클러스터를 실행할 머신에 로그인 후 실행시킬 스크립트와 마스터 프로세스 URI를 입력해 워커 노드를 시작 - 마스터 노드는 워커 노드와 네트워크 통신이 가능해야하며 마스터 프로세스 URI의 포트 역시 열려있어야 함\n",
    "```\n",
    "$SPARK_HOME/sbin/start-slave.sh <마스터-스파크-프로세스-URI>\n",
    "```\n",
    "\n",
    "#### 스크립트를 이용한 스탠드얼론 클로스터 시작하기\n",
    "- 시작 스크립트를 설정해 스탠드얼론 클러스터의 시작을 자동화 할 수 있음\n",
    "- 스파크가 설치된 디렉토리 하위에 conf/slaves 파일을 생성 - slaves 파일에 스파크 워커로 사용할 모든 머신의 호스트명을 한 줄에 하나씩 기록(이 파일이 없으면 모든 데몬이 로컬에서 실행) - 클러스터를 실행할 때 마스터 머신은 모든 워커 머신에 SSH를 이용해 접근(SSH는 병렬로 실행되며 개인키를 이용해 비밀번호 없이 로그인하는 방식) - 해당 방식 사용 불가하다면 SPARK_SSH_FOREGROUND 환경변수 설정하여 워커 노드에 접근할 때 마다 비밀번호 입력 - 하둡 배포 스크립트 기반의 다음의 셸 스크립트 사용하여 클러스터를 시작 or 중지(이들 스크립트는 SPARK_HOME/sbin 디렉토리에 존재)\n",
    "    - SPARK_HOME/sbin/start-master.sh: 스크립트를 실행한 머신에서 마스터 인스턴스를 시작합니다.\n",
    "    - SPARK_HOME/sbin/start-slaves.sh: confg/slaves 파일에 명시된 각 머신에서 슬레이브 인스턴스를 시작합니다.\n",
    "    - SPARK_HOME/sbin/start-slave.sh: 스크립트를 실행한 머신에서 슬레이브 인스턴스를 시작합니다.\n",
    "    - SPARK_HOME/sbin/start-all.sh: 마스터 인스턴스를 시작하고 conf/slaves 파일에 명시한 각 머신에서 슬레이브 인스턴스를 시작합니다.\n",
    "    - SPARK_HOME/sbin/stop-master.sh: bin/start-master.sh 스크립트로 시작한 마스터 인스턴스를 중지시킵니다.\n",
    "    - SPARK_HOME/sbin/stop-slaves.sh: conf/slaves 파일에 명시한 각 머신에서 슬레이브 인스턴스를 중지시킵니다.\n",
    "    - SPARK_HOME/sbin/stop-all.sh: 마스터 인스턴스를 중지시키고 conf/slaves 파일에 명시한 각 머신에서 슬레이브 인스턴스를 중지시킵니다.\n",
    "\n",
    "#### 스탠드얼론 클러스터 설정\n",
    "- 튜닝에 필요한 여러가지 설정 존재\n",
    "- 종료된 애플리케이션의 워커별 작업 파일 ~ 워커의 코어와 메모리까지 제어\n",
    "- 설정은 환경변수나 애플리케이션의 속성으로 정의\n",
    "\n",
    "#### 애플리케이션 제출하기\n",
    "- 클러스터를 생성하면 마스터 프로세스의 URI를 이용해 마스터 노드나 spark-submit 명령을 사용할 수 있는 머신에서 애플리케이션 제출 가능\n",
    "- 16.4절 애플리케이션 싲가하기에서 특정 명령행 인수 확인 가능\n",
    "\n",
    "### 17.2.2 YARN에서 스파크 실행하기\n",
    "- 잡 스케줄링과 클러스터 자원 관리용 프레임워크\n",
    "- 스파크는 기본적으로 하둡 YARN 클러스터 매니저를 지원하지만 하둡 자체가 필요한 것은 아님(스파크를 하둡 에코시스템의 일부로 착각해 잘못 분류하는 경우 존재)\n",
    "- spark-submit 명령의 --master 인수를 yarn으로 지정해 하둡 YARN 클러스터에서 스파크 잡을 실행할 수 있음\n",
    "- 스탠드얼론 클러스터 모드와 마찬가지로 클러스터 동작 방식을 제어할 수 있는 여러 기능 제공\n",
    "- 다양한 실행 프레임워크를 지원하는 통합 스케줄러\n",
    "- 자세한 내용은 하둡완벽가이드 참고 요망\n",
    "\n",
    "#### 애플리케이션 제출하기\n",
    "- --master 인수의 값을 yarn으로 지정\n",
    "\n",
    "### 17.2.3 YARN 환경의 스파크 애플리케이션 설정하기\n",
    "- 다양한 설정과 스파크 애플리케이션에 미치는 영향 이해 필요\n",
    "\n",
    "#### 하둡 설정\n",
    "- 스파크를 이용해 HDFS 파일을 읽고 쓰려면 스파크 클래스패스에 두 개의 하둡 설정 파일을 포함시켜야 한다.\n",
    "- HDFS 클라이언트 동작 방식을 결정하는 hdfs-site.xml & 기본 파일 시스템의 이름을 설정하는 core-site.xml\n",
    "- 하둡 버전에 따라 위치는 가변적이나 보통 /etc/hadoop/conf 하위에 설정 파일이 존재\n",
    "- 관리형 서비스에서 하둡 설정 파일을 어떻게 배포하는지 이해하는 것이 중요\n",
    "- 스파크에서 하둡 설정 파일 사용\n",
    "    - $SPARK_HOME/spark-env.sh 파일의 HADOOP_CONF_DIF 변수값을 하둡 설정 파일 경로로 지정\n",
    "    - spark-submit 명령으로 애플리케이션을 실행할 때 환경변수로 지정\n",
    "\n",
    "#### YARN 애플리케이션 속성\n",
    "- 하둡 설정이나 기능 중 YARN의 실행과 보안에 관련 설정은 스파크에 영향 있음.\n",
    "- 관련 설정은 스파크 공식 문서에서 YARN 설정 표를 참고\n",
    "\n",
    "### 17.2.4 메소스에서 스파크 실행하기\n",
    "- 메소스 프로젝트는 여러 스파크 개발자가 시작\n",
    "- 아파치 메소스는 CPU, 메모리, 저장소 그리고 다른 연산 자원을 머신에서 추상화합니다. 이를 통해 내고장성 및 탄력적 분산 시스템을 쉽게 구성하고 효과적으로 실행할 수 있습니다.\n",
    "- 스파크처럼 짧게 실행되는 애플리케이션 관리 가능 + 웹 애플리케이션 및 다른 자원 인터페이스 등 오래 실행되는 애플리케이션까지 관리할 수 있는 데이터센터 규모의 클러스터 매니저를 지향\n",
    "- 스파크에서 지원하는 클러스터 매니저 중 가장 무거움\n",
    "- 대규모의 메소스 배포 환경이 있는 경우에만 사용할 것 권장\n",
    "- 거대한 인프라 구조\n",
    "- 자세한 내용은 Mastering Mesos에서 참고\n",
    "- 두 가지 모드로 스파크 실행 -> 현재는 coarse-graind 스케줄링 모드만 지원\n",
    "    - fine-grained\n",
    "    - coarse-grained: 스파크 익스큐터를 단일 메소스 태스크로 실행(스파크 익스큐터는 아래 애플리케이션 속성에 따라 크기 조절)\n",
    "        - spark.executor.memory\n",
    "        - spark.executor.cores\n",
    "        - spark.cores.max / spark.executor.cores\n",
    "#### 애플리케이션 제출하기\n",
    "- cluster 모드 방식이 가장 적절 / client 모드를 사용하려면 클러스터 분산 자원 관리와 관련된 추가 설정 필요\n",
    "\n",
    "#### 메소스 설정하기\n",
    "\n",
    "### 17.2.5 보안 관련 설정\n",
    "- 신뢰도가 낮은 환경에서 애플리케이션 안전하게 실행할 수 있도록 저수준 API 기능을 지원\n",
    "- 인증, 네트워크 구간 암호화, TLS와 SSL 설정 가능\n",
    "\n",
    "### 17.2.6 클러스터 네트워크 설정\n",
    "- 클러스터 노드 사이에서 proxy를 사용하기 위해 스파크 클러스터에 사용자 정의 배포 설정을 적용할 경우 도움이 된다.\n",
    "- 스파크의 성능을 높이고 싶다면 사용자가 정의한 배포 시나리오에 맞게 적용해야 한다.\n",
    "\n",
    "### 17.2.7 애플리케이션 스케줄링\n",
    "- 스파크 애플리케이션은 독립적인 익스큐터 프로세스를 실행\n",
    "- 스파크 애플리케이션에서 여러 개의 잡(스파크 액션)을 다른 스레드가 제출할 경우 동시 실행 가능\n",
    "    - 네트워크를 통한 요청에 응답하는 애플리케이션에 적합\n",
    "    - 스파크는 애플리케이션에서 자원을 스케줄링할 수 있도록 페어 스케줄러 기능을 제공\n",
    "- 동적할당: 대기 중인 태스크 수에 따라 애플리케이션을 동적으로 확장 축소 할 수 있음\n",
    "- 익스큐터의 자원과 메모리를 공유하려면 단일 스파크 애플리케이션을 실행하고 스레드 스케줄링을 이용해 병렬로 요청 처리\n",
    "\n",
    "#### 동적 할당\n",
    "- 사용자 애플리케이션이 사용하지 않는 자원을 클러스터에 반환하고 필요할 대 다시 요청하는 방식\n",
    "- 다수의 애플리케이션이 스파크 클러스터의 자원을 함게 사용해야하는 상황에서 유용\n",
    "- 스탠드얼론 모드와 YARN, 메소스 coarse-grained 모드에서 사용 가능\n",
    "- 기본값은 '사용하지 않음' -> '사용함'으로 변경하고 싶다면 두 가지 설정 변경 필요\n",
    "    - 애플리케이션: spark.dynamicAllocation.enabled 속성을 true로 지정 + spark.shuffle.service.enabled true로 지정\n",
    "    - 워커 노드: 외부 셔플 서비스를 사용하도록 설정\n",
    "\n",
    "## 17.3 기타 고려사항\n",
    "- 애플리케이션의 개수와 유형\n",
    "    - YARN의 경우: HDFS를 사용하는 애플리케이션 실행 시 적합하나 그 외 경우에 잘 사용하지X + 연산용 클러스터와 저장소 클러스터가 강하게 결합 => 연산용 클러스터와 저장소 클러스터를 동시에 확장해야 함.\n",
    "    - 메소스의 경우 YARN이 가진 개념을 개선, 다양한 애플리케이션 유형을 지원. 더 큰 규모의 클러스터에 적합 => 스파크 애플리케이션만 실행하려고 메소스 클러스터를 구축하는 것은 권장X\n",
    "    - 스파크 스탠드얼론 클런스터는 가장 가벼운 클러스터 매니저이며 비교적 이해와 활용이 쉬우나, 더 많은 애플리케이션 관리하는 인프라 구조를 구축해야한다면 YARN/메소스 사용이 나을 수 있음\n",
    "- 다양한 스파크 버전 관리 문제\n",
    "    - 버전별 설정 스크립트 관리 or 스파크 버전 제한\n",
    "- 애플리케이션 디버깅에 필요한 로그 기록 방식\n",
    "    - YARN, 메소스의 경우 로그 기록 기능을 기본으로 제공 / 스탠드얼론 모드는 수정 필요\n",
    "- 테이블 카탈로그 같은 저장된 데이터셋의 메타데이터를 관리하기 위한 메타스토어 사용 고려 필요\n",
    "    - 아파치 하이브 메타스토어를 사용하면 같은 데이터셋을 참조하는 여러 애플리케이션의 생산성 증가 가능\n",
    "- 워크로드 특성에 맞춰 외부 셔플 서비스 사용 필요 가능성\n",
    "- 클러스터에서 실행되는 스파크 잡을 디버깅하려면 최소 기본적인 모니터링 슐루션 필요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

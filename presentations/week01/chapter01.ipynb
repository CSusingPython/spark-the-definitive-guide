{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b205bf",
   "metadata": {},
   "source": [
    "# 아파치 스파크란\n",
    "* 통합 컴퓨팅 엔진\n",
    "* 클러스터 환경에서 데이터를 병렬로 처리하는 라이브러리 집합\n",
    "![spark-function-structure](../../assets/presentations/week01/spark-functional-structure.png)\n",
    "\n",
    "## 아파치 스파크의 철학\n",
    "* 통합\n",
    "  * 간단한 데이터 읽기에서부터 SQL 처리, 머신러닝 그리고 스트림 처리에 이르기까지 다양한 데이터 분석 작업을 같은 연산 엔진과 일관성 있는 API로 수행할 수 있도록 설계\n",
    "* 컴퓨팅 엔진\n",
    "  * 데이터를 연산하는 역할만 수행할 뿐 영구 저장소 역할은 수행하지 않음\n",
    "  * 대부분 여러 저장소 시스템에 혼재되어 데이터 저장되고, 데이터의 이동은 높은 비용을 유발하기 때문\n",
    "  * 아래 저장소를 지원\n",
    "    * 클라우드 기반 애저 스토리지\n",
    "    * 아마존 S3\n",
    "    * 분산 파일 시스템 아파치 하둡\n",
    "    * 키/값 저장소 아파치 카산드라\n",
    "    * 메시지 전달 서비스 아파치 카프카\n",
    "* 라이브러리\n",
    "  * 엔진에서 제공하는 표준 라이브러리와 오픈 소스 커뮤니티에서 서드파티 패키지 형태로 제공하는 다양한 외부 라이브러리 지원\n",
    "\n",
    "## 스파크 등장 배경\n",
    "* 이전에는 더 많은 연산과 대규모 데이터 처리를 프로세서의 성능 향상에 맡겼으나, 물리적인 방열 한계로 단일 프로세서의 성능을 향상시키는 방법 대신 모든 코어가 같은 속도로 동작하는 병렬 CPU 코어를 더 많이 추가하는 방향으로 선회\n",
    "* 데이터 수집 비용이 저렴해져 데이터는 클러스터에서 처리해야 할 만큼 거대해짐\n",
    "\n",
    "## 스파크의 역사\n",
    "* UC 버클리 대학교에서 2009년 스파크 연구 프로젝트로 시작\n",
    "* 1.0 이전의 스파크 초기 버전은 함수형 연산 관점에서 API를 정의\n",
    "* 스파크 1.0 버전부터 구조화된 데이터를 기반으로 동작하는 신규 API인 스파크 SQL 추가됨\n",
    "* 이후 DataFrame, 머신러닝 파이프라인, 자동 최적화를 수행하는 구조의 스트리밍 등 더 강력한 구조체 기반 신규 API 추가\n",
    "\n",
    "## 스파크의 현재와 미래\n",
    "* 활용 사례가 늘어나고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9186b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
